[project]
name = "quore"
version = "0.1.0"
description = ""
authors = [
    {name = "mustela",email = "ejankowski@gmail.com"}
]
packages = [
    { include = "app" }
]
readme = "README.md"
requires-python = ">=3.11"

[tool.poetry]
packages = [
    { include = "app" }
]

[tool.poetry.scripts]
dev = "run:dev"

[tool.poetry.dependencies]
python = ">=3.11,<3.14"
fastapi = "^0.115.11"
python-dotenv = "^1.0.0"
sqlalchemy = "^2.0.39"
asyncpg = "^0.29.0"
gunicorn = "^23.0.0"
alembic = "^1.15.1"
faker = "^37.1.0"
psycopg2-binary = "^2.9.10"
pydantic = {extras = ["email"], version = "^2.11.3"}
black = "^25.1.0"
ruff = "^0.11.6"
pydantic-settings = "^2.9.1"
python-jose = "^3.3.0"
opentelemetry-instrumentation-fastapi = "^0.53b1"
opentelemetry-exporter-otlp-proto-grpc = "^1.32.1"
opentelemetry-sdk = "^1.32.1"
requests = "^2.32.3"
opentelemetry-instrumentation-sqlalchemy = "^0.53b1"
pyjwt = "^2.10.1"
sqlalchemy-json = "^0.7.0"
llama-index = "^0.12.34"
llama-index-vector-stores-postgres = "^0.5.1"
llama-index-embeddings-openai = "^0.3.1"
llama-index-embeddings-huggingface = "^0.5.3"
llama-index-embeddings-ollama = "^0.6.0"
cryptography = "^44.0.3"
llama-index-core = "^0.12.35"
llama-index-utils-workflow = "^0.3.2"
llama-index-llms-ollama = "^0.5.4"
llama-index-llms-openai = "^0.3.38"
llama-index-llms-huggingface = "^0.5.0"
llama-index-storage-docstore-redis = "^0.3.0"
# https://github.com/run-llama/llama_index/blob/main/llama-index-integrations/storage/chat_store/llama-index-storage-chat-store-postgres/pyproject.toml
llama-index-storage-chat-store-postgres = "^0.2.1"
fernet = "^1.0.1"
celery = "^5.5.2"

[tool.poetry.dependencies.uvicorn]
extras = [ "standard" ]
version = "^0.23.2"

[tool.poetry.group.dev.dependencies]
pytest = "^8.0.0"
httpx = "^0.27.0"  # Required by FastAPI TestClient

[build-system]
requires = ["poetry-core>=2.0.0,<3.0.0"]
build-backend = "poetry.core.masonry.api"
